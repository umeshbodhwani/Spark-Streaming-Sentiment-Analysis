{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>init spark</h1>\n",
    "<li>The driver_memory step is important since streaming apps take up a lot of memory</li>\n",
    "<li>A few new jars:</li>\n",
    "<ul>\n",
    "    <li>twitter streaming api jar</li>\n",
    "    <li>jfreechart jars for drawing charts</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%init_spark\n",
    "launcher.num_executors = 4\n",
    "launcher.executor_cores = 2\n",
    "launcher.driver_memory = '10g'\n",
    "launcher.packages= [\"databricks:spark-corenlp:0.4.0-spark2.4-scala2.11\", \"org.apache.bahir:spark-streaming-twitter_2.11:2.4.0\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>CoreNLP imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.util.Properties \n",
    "import scala.collection.JavaConverters._\n",
    "import edu.stanford.nlp.ling.CoreAnnotations \n",
    "import edu.stanford.nlp.neural.rnn.RNNCoreAnnotations \n",
    "import edu.stanford.nlp.neural.rnn.RNNCoreAnnotations \n",
    "import edu.stanford.nlp.pipeline.{Annotation, StanfordCoreNLP}\n",
    "import edu.stanford.nlp.sentiment.SentimentCoreAnnotations\n",
    "import scala.collection.convert.wrapAll._\n",
    "import scala.collection.mutable.ArrayBuffer\n",
    "import org.apache.spark.sql.DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Parameters</h2>\n",
    "<li><span style=\"color:blue\">BATCH_SIZE</span>: The size of a micro batch</li>\n",
    "<li><span style=\"color:blue\">NUM_BATCHES</span>: The minumum amount of data you need to collect. Ideally, of course, this should run for ever!</li>\n",
    "<li><span style=\"color:blue\">WINDOW_LENGTH</span>: The size of a window. We're collecting data in small batches, a window in this instance is like constructing a moving average. Roughly, we're collecting a moving 5 minute moving average of data averaged every minute</li>\n",
    "<li><span style=\"color:blue\">SLIDE_DURATION</span>: The slide duration. Since we're reproducing a moving average, we'll keep this at the batch size</li>\n",
    "<li><span style=\"color:blue\">TWEET_WORDS</span>: The tweets we will examine. Each tweet in our moving average should contain at least one word from this list</li>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val BATCH_SIZE = 60\n",
    "val NUM_BATCHES = 20\n",
    "val WINDOW_LENGTH = 300\n",
    "val SLIDE_DURATION = BATCH_SIZE\n",
    "//val tweet_words = Array(\"aapl\",\"apple\",\"mac\",\"ipad\",\"iphone\")\n",
    "val TWEET_WORDS = Array(\"covid\",\"corona\",\"virus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>getSentiment</h2>\n",
    "<li>A function that returns the sentiment given a piece of text</li>\n",
    "<li>Get the sentence for each sentence in the text and divide by the number of sentences</li>\n",
    "<li>(This is the stanford corenlp part!)\n",
    "<li>Returns a Double</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Twitter keys</h2>\n",
    "<li>Get twitter API keys <a href=\"https://developer.twitter.com/en/docs/basics/getting-started\">Getting started with twitter API</a> (use the standard API)</li>\n",
    "<li>Enter them below</li>\n",
    "<li>Then assign them to various twitter4j objects</li>\n",
    "<li>Finally, create the stream receiver</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h3>Create a DStream with <span style=\"color:blue\">(text,sentiment)</span> pairs</h3>\n",
    "<li>the function, getText, returns the text of a tweet</li>\n",
    "<li>Note: You will need to include the getSentiment function in this cell</li>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Filter the text_sentiment_array to include only tweets with words in our TWEET_WORDS array</h3>\n",
    "<li>Also, throw away the text (i.e., return a DStream of Double)</li>\n",
    "<li>Save this in an DStream of Double <span style=\"color:blue\">sentiment_array</span></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create and update an array that holds the moving average</h3>\n",
    "<li>for each window, we will report the average sentiment in that window (all tweet sentiments/number of tweets) - note that this is not exactly a moving average in time terms</li>\n",
    "<li>the main reason for doing this is that we may not get tweets in every window and then will have to deal with nans. Too complicated!</li>\n",
    "<li>The method below is:\n",
    "    <ul>\n",
    "        <li>sentiment_window contains the sentiment of each tweet in the window</li>\n",
    "        <li>using foreachRDD, and a function getAverages, calculate the average sentiment for that window</li>\n",
    "        <li>getAverage should calculate (timestamp, sentiment) pair for each window<li>\n",
    "<li>We also need to clean the timestamp. Convert it into a string, drop the \"ms\" from the end, and then drop everything other than last 7 digits</li>\n",
    "<li><b>Note</b>: Bear in mind that while DStream objects do not persist, Scala objects, RDDs, etc. do persist. Once the stream stops, these non-DStream objects are still accessible in your program</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Create the chart</h1>\n",
    "<li>We will create an xy graph</li>\n",
    "<li><a href=\"http://www.jfree.org/jfreechart/api/javadoc/org/jfree/data/xy/XYSeries.html\">http://www.jfree.org/jfreechart/api/javadoc/org/jfree/data/xy/XYSeries.html</a></li>\n",
    "<li>x-axis contains the time stamp (last 7 digits) of the window. We need to convert this into an Int (x-axis is scaled)</li>\n",
    "<li>y-axis contains the average sentiment of the window</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//All imports\n",
    "import java.util.Properties \n",
    "import scala.collection.JavaConverters._\n",
    "import edu.stanford.nlp.ling.CoreAnnotations \n",
    "import edu.stanford.nlp.neural.rnn.RNNCoreAnnotations \n",
    "import edu.stanford.nlp.neural.rnn.RNNCoreAnnotations \n",
    "import edu.stanford.nlp.pipeline.{Annotation, StanfordCoreNLP}\n",
    "import edu.stanford.nlp.sentiment.SentimentCoreAnnotations\n",
    "import scala.collection.convert.wrapAll._\n",
    "import scala.collection.mutable.ArrayBuffer\n",
    "import org.apache.spark.sql.DataFrame\n",
    "\n",
    "//JFreeChart imports\n",
    "import java.awt.Color \n",
    "import org.apache.log4j.{Level, Logger} \n",
    "import org.apache.spark.sql.SparkSession \n",
    "import org.jfree.chart.plot.{PlotOrientation, XYPlot} \n",
    "import org.jfree.chart.{ChartFactory, ChartFrame, JFreeChart, ChartUtilities} \n",
    "import org.jfree.data.xy.{XYSeries, XYSeriesCollection} \n",
    "import scala.util.Random \n",
    "\n",
    "\n",
    "\n",
    "//All parameters\n",
    "val BATCH_SIZE = 60\n",
    "val NUM_BATCHES = 20\n",
    "val WINDOW_LENGTH = 300\n",
    "val SLIDE_DURATION = 60\n",
    "\n",
    "//getSentiment function\n",
    "\n",
    "def getSentiment(text: String): Double = {\n",
    "    val props = new Properties()\n",
    "    props.setProperty(\"annotators\", \"tokenize, ssplit, pos, parse, sentiment\")\n",
    "    val pipeline: StanfordCoreNLP = new StanfordCoreNLP(props)\n",
    "\n",
    "\n",
    "    val annotation: Annotation = pipeline.process(text)\n",
    "    val sentences = annotation.get(classOf[CoreAnnotations.SentencesAnnotation])\n",
    "    val score = sentences.map { sent => \n",
    "        val tree = sent.get(classOf[SentimentCoreAnnotations.SentimentAnnotatedTree])\n",
    "        val score = RNNCoreAnnotations.getPredictedClass(tree)\n",
    "        score\n",
    "    }\n",
    "    score.toArray.sum.toDouble/score.size\n",
    "}\n",
    "\n",
    "//val words = Array(\"covid\",\"corona\",\"virus\")\n",
    "val words = Array(\"aapl\",\"apple\",\"mac\",\"ipad\",\"iphone\")\n",
    "\n",
    "//filterData function\n",
    "def filterData(text: String,words: Array[String]): Boolean =\n",
    "    words.exists(text.contains)\n",
    "\n",
    "//Twitter API keys\n",
    "\n",
    "val CONSUMER_KEY = \n",
    "val CONSUMER_SECRET = \n",
    "val ACCESS_TOKEN = \n",
    "val ACCESS_TOKEN_SECRET = \n",
    "\n",
    "//Twitter API keys attached to twitter4j\n",
    "System.setProperty(\"twitter4j.oauth.consumerKey\",CONSUMER_KEY)\n",
    "System.setProperty(\"twitter4j.oauth.consumerSecret\",CONSUMER_SECRET)\n",
    "System.setProperty(\"twitter4j.oauth.accessToken\",ACCESS_TOKEN)\n",
    "System.setProperty(\"twitter4j.oauth.accessTokenSecret\",ACCESS_TOKEN_SECRET)\n",
    "\n",
    "\n",
    "//Streaming context and twitter stream set up\n",
    "import org.apache.spark.streaming.{Seconds, StreamingContext}\n",
    "import org.apache.spark.streaming.twitter._\n",
    "val ssc = new StreamingContext(sc,Seconds(BATCH_SIZE.toLong))\n",
    "\n",
    "val stream = TwitterUtils.createStream(ssc, None)\n",
    "val tweets = stream.filter(_.getLang == \"en\")\n",
    "\n",
    "\n",
    "//text_sentiment_pairs\n",
    "val text_sentiment_pairs = tweets.map { status =>\n",
    "        val text = status.getText.toLowerCase\n",
    "        val sentiment = getSentiment(text)\n",
    "        (text,sentiment)\n",
    "    }\n",
    "\n",
    "\n",
    "//sentiment_array\n",
    "val sentiment_array = text_sentiment_pairs.filter(l => filterData(l._1,words)).map(l=>l._2)\n",
    "\n",
    "//Window definition\n",
    "val sentiment_window = sentiment_array.window(Seconds(WINDOW_LENGTH),Seconds(SLIDE_DURATION))\n",
    "\n",
    "//FUNCTIONALITY FOR WINDOW AVERAGES\n",
    "//An ArrayBuffer to hold each (timestamp, average) pair\n",
    "val all_averages = ArrayBuffer[(String,Double)]()\n",
    "\n",
    "//getAverage function\n",
    "def getAverage(sentiments: Array[Double], aa: ArrayBuffer[(String,Double)],t: String) = {\n",
    "    val new_avg = sentiments.sum/sentiments.length\n",
    "    val clean_timestamp = t.split(\" \")(0).takeRight(7)\n",
    "    aa+=((clean_timestamp,new_avg))\n",
    "}\n",
    "\n",
    "//compute average for a window and add it, timestamped to all_averages\n",
    "sentiment_window.foreachRDD((r,t) => {\n",
    "    //println(r.count,r.sum)\n",
    "    getAverage(r.collect(),all_averages,t.toString)\n",
    "    println(all_averages)\n",
    "})\n",
    "\n",
    "\n",
    "//Create a new XYSeries object that holds the data for the graph\n",
    "//And a dataset that contains this XYSeries object\n",
    "//The goal is to update xy whenever there is a new average in all_averages\n",
    "\n",
    "val xy = new XYSeries(\"\") \n",
    "val dataset = new XYSeriesCollection(xy)\n",
    "\n",
    "//Creates the chart object (done for you)\n",
    "val chart = ChartFactory.createXYLineChart( \n",
    "  \"Sentiment Chart\",  // chart title \n",
    "  \"Time\",               // x axis label \n",
    "  \"Sentiment\",                   // y axis label \n",
    "  dataset,                   // data \n",
    "  PlotOrientation.VERTICAL, \n",
    "  false,                    // include legend \n",
    "  true,                     // tooltips \n",
    "  false                     // urls \n",
    ")\n",
    "\n",
    "//From the chart, grab the blot so that we can configure formatting info\n",
    "val plot = chart.getXYPlot() \n",
    "\n",
    "def configurePlot(plot: XYPlot): Unit = { \n",
    "  plot.setBackgroundPaint(Color.WHITE) \n",
    "  plot.setDomainGridlinePaint(Color.BLACK) \n",
    "  plot.setRangeGridlinePaint(Color.BLACK) \n",
    "  plot.setOutlineVisible(false) \n",
    "} \n",
    "\n",
    "//A function that shows the chart. This, when called, will pop up the chartin a separate window.// \n",
    "\n",
    "def show(chart: JFreeChart) { \n",
    "  val frame = new ChartFrame(\"plot\", chart) \n",
    "  frame.pack() \n",
    "  frame.setVisible(true) \n",
    "}\n",
    "\n",
    "//Call the plot configuration function\n",
    "//Call the show chart function (now it will actually pop up)\n",
    "configurePlot(plot) \n",
    "show(chart)\n",
    "\n",
    "\n",
    "//Start the stream\n",
    "//Inside a while loop, sleep for a bit\n",
    "//then check if there are new elements in all_averages\n",
    "//if there are new elements, add them to xy using addOrUpdate (see documentation linked above)\n",
    "//you can do this in many ways but easy way is to keep a record of the current length\n",
    "//check if the new length of the array is greater than the recorded length\n",
    "//if it is, add the elements in all_averages.length - previous_length to xy\n",
    "\n",
    "//Use addOrUpdate (not add) so that the graph updates\n",
    "//Use Thread.sleep(n) to sleep n-seconds (10000, or 10 seconds should work well)\n",
    "\n",
    "//The while should run as long as the length of all_averages is less than NUM_BATCHES\n",
    "//Call ssc.stop(false) after the while loop\n",
    "\n",
    "//Enjoy!\n",
    "var index = 0\n",
    "ssc.start\n",
    "while (all_averages.length < NUM_BATCHES ) {\n",
    "    Thread.sleep(10000);\n",
    "    var len = all_averages.length\n",
    "    if (len > index) {\n",
    "        all_averages.takeRight(len-index).toArray.foreach{ case (x: String, y: Double) => xy.addOrUpdate(x.toInt,y) } \n",
    "        index = len\n",
    "    }\n",
    "}\n",
    "ssc.stop(false)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
